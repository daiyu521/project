{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.Data Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1 Reprocess the Orignal Dataset from internet**\n",
    "#### I obtained the Singapore 2020 Q1 retail rental dataset from Singapore Government official website. https://www.ura.gov.sg/-/media/Corporate/Property/Commercial-Properties-2020Q1/comm_median_rentals_2020Q1.pdf?la=en. The Dataset contains the information of Rental rates of different Singapore Streets per square feet for retails and offices in Q1 2020. Below graph is an example of the dataset in pdf format. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-9/95822767_10159578945168906_9077220140927418368_n.jpg?_nc_cat=110&_nc_sid=8024bb&_nc_ohc=H3XUYh603usAX-bHAOD&_nc_ht=scontent.fsin5-1.fna&oh=70d22d788ef9e33292860dd35a6a63a4&oe=5EDEE2CB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As mentioned above, the original file is a pdf format file. I tried to using Tabula.read_pdf function to extract the table from the original pdf file but failed to do so in the end. Thus, I downloaded the data directly from the link and converted it to CSV file in my computer. I did the data cleaning for the missing values and  the unwanted columns in the CSV file by using excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-9/97054859_10159578944933906_4509786845587963904_n.jpg?_nc_cat=110&_nc_sid=8024bb&_nc_ohc=pKXeiMJbvksAX_zL8T9&_nc_ht=scontent.fsin5-1.fna&oh=594bc91ffbe02c80ae91319f76dbf604&oe=5EDF2CBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  After data cleaning, the CSV file was uploaded to IBM Db2 on cloud. Use SQL magic retrieve the data and convert to dataframe in the Jupyter notebook. With this dataframe, we could predict locations with ideal rental rate and analysis further by using Foursquar API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-9/96510216_10159578944978906_6024643637910962176_n.jpg?_nc_cat=110&_nc_sid=8024bb&_nc_ohc=frXJrIlklk4AX8qe1Ju&_nc_ht=scontent.fsin5-1.fna&oh=433179366541b8d3ad04950312762804&oe=5EDEF9E0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2 Retrieve all the Latitudes and longitudes for all the streets in the dataframe**\n",
    "#### By installation of Geopy package, all the location details for the streets in the dataframe could be found out. We could retrieve the Latitudes and Longitudes as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-9/96136989_10159578945838906_1080355970556624896_n.jpg?_nc_cat=109&_nc_sid=8024bb&_nc_ohc=kwCbxJhkDxoAX-EYVfV&_nc_ht=scontent.fsin5-1.fna&oh=86d5939c846fd9159a39db7c95c55083&oe=5EDBEA1E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3 Get Near-by-venues occurrence frequency for all the streets in the dataframe**\n",
    "#### After getting all the latitudes and longitudes, it was ready to connect with Foursquare API to explore the near-by-venues for all the streets. The Foursquare Credentials and version were defined before I explored. For the first street I explored, I got the top 100 venues that are in the street within a radius of 500 meters. I borrowed the get_category_type function from the Foursquare lab to clean the json and structure it into a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-9/96418211_10159578945908906_8757998534898221056_n.jpg?_nc_cat=108&_nc_sid=8024bb&_nc_ohc=LBcxnyahJVoAX9rzc5A&_nc_ht=scontent.fsin5-1.fna&oh=32354b20650b95345a610cb093f96db0&oe=5EDC4999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I repeated the above process for all the streets in the dataframe. and grouped the rows by neighborhood (street name) and by taking the mean of the frequency of occurrence of each category. Now it was ready to analysis the near-by-venues to determine the suitable locations to start a new spa business: any bus stop or MRT station there? Any spa centres already opened there? Is there near to the shopping mall or hotel? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://scontent.fsin5-1.fna.fbcdn.net/v/t1.0-9/95857793_10159578946313906_761677948473311232_n.jpg?_nc_cat=101&_nc_sid=8024bb&_nc_ohc=KVEevcUqDvoAX_5uQfI&_nc_ht=scontent.fsin5-1.fna&oh=dd7c60d6ce456611676edca3ff4ab278&oe=5EDEFA44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
